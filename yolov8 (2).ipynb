{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3866417,"sourceType":"datasetVersion","datasetId":843852}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pytorch_lightning as pl\nfrom torch.utils.data import DataLoader, Dataset\nimport os\nimport torch\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:46:19.079412Z","iopub.execute_input":"2024-08-05T14:46:19.079939Z","iopub.status.idle":"2024-08-05T14:46:26.828413Z","shell.execute_reply.started":"2024-08-05T14:46:19.079910Z","shell.execute_reply":"2024-08-05T14:46:26.827623Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class YOLODataset(Dataset):\n    def __init__(self, csv_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(csv_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n        # Check if dataset is empty\n        if len(self.img_labels) == 0:\n            raise ValueError(\"Dataset is empty. Please check the CSV file and the image directory.\")\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n        if not os.path.exists(img_path):\n            raise FileNotFoundError(f\"Image file {img_path} not found.\")\n        image = Image.open(img_path).convert(\"RGB\")\n\n        # Extract bounding box and class probabilities\n        labels = self.img_labels.iloc[idx, 1:].values.astype(float)\n        labels = torch.tensor(labels, dtype=torch.float32)  # Convert labels to Float32\n\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            labels = self.target_transform(labels)\n\n        return {'image': image, 'label': labels}","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:46:26.829947Z","iopub.execute_input":"2024-08-05T14:46:26.830357Z","iopub.status.idle":"2024-08-05T14:46:26.839772Z","shell.execute_reply.started":"2024-08-05T14:46:26.830331Z","shell.execute_reply":"2024-08-05T14:46:26.838676Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass ConvBlock(nn.Module):\n    #flag: Ã¨ una variable che abbiamo inserito per controllare la dimensione \n    #di out_channels per c2f blocco 12 \n    def __init__(self, k, s, p, c=3, dim=64, mc=512, w=1, flag=1):\n        super(ConvBlock, self).__init__()\n        dim = int(dim)\n        out = min(dim,mc)*w\n        self.conv = nn.Conv2d(in_channels=c, out_channels=out, kernel_size=k, stride=s, padding=p)\n        self.batch_norm = nn.BatchNorm2d(num_features=out)\n        self.activation = nn.SiLU()\n    \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.batch_norm(x)\n        x = self.activation(x)\n        return x\n    \n\nclass Bottleneck(nn.Module):\n    def __init__(self, k=3, s=1, p=1, c=3, dim=64, shortcut=True):\n        super(Bottleneck, self).__init__()\n        self.conv1 = ConvBlock(k,s,p,c,dim=dim,mc=512)\n        self.conv2 = ConvBlock(k,s,p,c,dim=dim,mc=512)\n        self.short = shortcut\n\n    \n    def forward(self, x):\n        #print(x.shape)\n        #print(self.conv1)\n        #print(self.conv2)\n        if self.short: \n            res = self.conv1(x)\n            res = self.conv2(res)\n            return x + res\n        else: \n            res = self.conv1(x)\n            res = self.conv2(x)\n            return res \n            \nclass C2fBlock(nn.Module):\n    def __init__(self, k=1, s=1, p=0, c=3, depth_multiple=1, shortcut=True, dim=64, mc=512, w=1, flag=1):\n        super(C2fBlock, self).__init__() \n        self.conv1 = ConvBlock(k=1,s=1,p=0,c=c,dim=dim,mc=mc,w=w,flag=flag)\n        half_c= int(dim / 2)\n        if half_c == 512:\n            half_dim = 512\n        else:\n            half_dim= int(dim / 2)\n            \n        if flag == 0: \n            self.bottlenecks = nn.ModuleList([Bottleneck(k=3,s=1,p=1,c=256,dim=256) for _ in range(depth_multiple)])\n            new_input = int(512 / 2) * (depth_multiple + 2)\n            self.conv2 = ConvBlock(k,s,p,c=new_input,dim=dim,mc=mc,w=w)\n        else:\n            self.bottlenecks = nn.ModuleList([Bottleneck(k=3,s=1,p=1,c=half_c,dim=half_dim) for _ in range(depth_multiple)])\n            new_input = int(dim / 2) * (depth_multiple + 2)\n            self.conv2 = ConvBlock(k,s,p,c=new_input,dim=dim,mc=mc,w=w)\n    \n    def forward(self, x):\n        \n        #print(f\"x_input: {x.shape}\")\n        x = self.conv1(x)\n              \n       # print(f\"x_conv1: {x.shape}\")\n        \n        # Split the input tensor into two halves along the channel dimension\n        x1, x2 = torch.split(x, x.size(1) // 2, dim=1)\n        \n        #print(f\"x1: {x1.shape}, x2: {x2.shape}\")\n        \n        \n        # Process the other half (x2) through the bottlenecks\n        bottleneck_outputs = []\n        # append half of the input before processing\n        bottleneck_outputs.append(x2.clone())\n        for bott in self.bottlenecks:\n            x2 = bott(x2)\n            bottleneck_outputs.append(x2.clone())\n            \n        # this will concatenate half of the input before processing\n        # and after each bottleneck processing  \n        \n        concatenated_bottleneck_outputs = torch.cat(bottleneck_outputs, dim=1)\n\n        # add the other half\n        x = torch.cat((x1, concatenated_bottleneck_outputs), dim=1)\n        #print(f\"x: {x.shape}, x1: {x1.shape}, conc: {concatenated_bottleneck_outputs.shape}\")\n        x = self.conv2(x)\n        return x\n    \nclass SPPF(nn.Module):\n    def __init__(self, k=3, s=1, p=0, c=3, dim=64):\n        super(SPPF, self).__init__() \n        \n        self.conv1 = ConvBlock(k=k,s=s,p=0,c=c,dim=dim)\n        self.pool1 = nn.MaxPool2d(kernel_size=5, stride=1, padding=2)\n        self.pool2 = nn.MaxPool2d(kernel_size=9, stride=1, padding=4)\n        self.pool3 = nn.MaxPool2d(kernel_size=13, stride=1, padding=6)\n        self.conv2 = ConvBlock(k=3,s=1,p=1,c=4*c,dim=dim)\n        \n    def forward(self, x):\n        \n        x = self.conv1(x)\n        pool1 = self.pool1(x)\n        pool2 = self.pool2(x)\n        pool3 = self.pool3(x)\n        #print(f\"x: {x.shape}, pool1: {pool1.shape}, pool2: {pool2.shape}, pool3: {pool3.shape}\")\n        x = torch.cat([x, pool1, pool2, pool3], dim=1)\n        #print(f\"x_conc: {x.shape}\")\n        x = self.conv2(x)\n        return x\n    \nclass DetectBlock(nn.Module):\n    def __init__(self, k=3, s=1, p=1, c=3, reg_max=16, nc=1, mc=512, w=1):\n        super(DetectBlock, self).__init__()\n        \n        #reg_max = controlla la precisione della regression sulla boundy box \n        #nc = number of classes\n        self.box_conv1 = ConvBlock(k,s,p,c=c,dim=64)\n        self.box_conv2 = ConvBlock(k,s,p,c=64,dim=64)\n        self.box_conv3 = nn.Conv2d(in_channels=64, out_channels=4*reg_max, kernel_size=k, stride=1, padding=0)\n        \n        self.class_conv1 = ConvBlock(k,s,p,c,dim=64)\n        self.class_conv2 = ConvBlock(k,s,p,c=64,dim=64)\n        self.class_conv3 = nn.Conv2d(in_channels=64, out_channels=nc, kernel_size=k, stride=1, padding=0)\n        \n    def forward(self, x): \n        ret1 = self.box_conv1(x)\n        ret1 = self.box_conv2(ret1)\n        ret1 = self.box_conv3(ret1)\n        \n        ret2 = self.class_conv1(x)\n        ret2 = self.class_conv2(ret2)\n        ret2 = self.class_conv3(ret2)\n        \n        return ret1, ret2\n               \nclass BackBone(nn.Module):\n    def __init__(self, k=3, s=2, p=1, depth=1):\n        super(BackBone, self).__init__()\n        \n        self.conv1 = ConvBlock(k,s,p)\n        self.conv2 = ConvBlock(k,s,p, dim=128, c=64)\n        self.c2f = C2fBlock(k=1,s=1,p=0,depth_multiple=3*depth,dim=128, c=128)\n        self.conv3 = ConvBlock(k,s,p, dim=256, c=128)\n        self.c2f_second = C2fBlock(k=1,s=1,p=0,depth_multiple=6*depth,dim=256, c=256)\n        self.conv4 = ConvBlock(k,s,p,dim=512, c=256)\n        self.c2f_third = C2fBlock(k=1,s=1,p=0,depth_multiple=6*depth,dim=512, c=512)\n        self.conv5 = ConvBlock(k,s,p,dim=1024, c=512)\n        self.c2f_last = C2fBlock(k=1,s=1,p=0,depth_multiple=3*depth,dim=min(1024,512), c=512)\n        \n    def forward(self, x):\n        if DEBUG:\n            print(\"[Layer: Conv 0]\")\n            print(f\"Input Tensor Shape:  {x.shape}\")\n        x = self.conv1(x)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: Conv 1]\")\n            print(f\"Input Tensor Shape:  {x.shape}\")\n        x = self.conv2(x)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: C2f 2]\")\n            print(f\"Input Tensor Shape:  {x.shape}\")\n        x = self.c2f(x)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: Conv 3]\")\n            print(f\"Input Tensor Shape:  {x.shape}\")        \n        x = self.conv3(x)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: C2f 4]\")\n            print(f\"Input Tensor Shape:  {x.shape}\") \n        x_first = self.c2f_second(x)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x_first.shape}\")\n\n            print(\"[Layer: Conv 5]\")\n            print(f\"Input Tensor Shape:  {x_first.shape}\") \n        x = self.conv4(x_first)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: C2f 6]\")\n            print(f\"Input Tensor Shape:  {x.shape}\") \n        x_second = self.c2f_third(x)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x_second.shape}\")\n\n            print(\"[Layer: Conv 7]\")\n            print(f\"Input Tensor Shape:  {x_second.shape}\")\n        x = self.conv5(x_second)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: C2f 8]\")\n            print(f\"Input Tensor Shape:  {x.shape}\")\n        x_last = self.c2f_last(x)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x_last.shape}\")\n        \n        return x_first, x_second, x_last\n    \nclass Neck(nn.Module):\n    def __init__(self, depth=1, scale=2):\n        super(Neck, self).__init__()\n        \n        self.sppf = SPPF(k=1,dim=1024,c=512)\n        self.upsample1 = nn.Upsample(size=(24,24))\n        self.upsample2 = nn.Upsample(scale_factor=2)\n        self.c2f_block1 = C2fBlock(dim=512,c=1024,flag=1,shortcut=False)\n        self.c2f_block2 = C2fBlock(dim=256,c=768,flag=1,shortcut=False) \n        self.c2f_block3 = C2fBlock(dim=512,c=768,flag=1,shortcut=False)\n        self.c2f_block4 = C2fBlock(dim=1024,c=1024,flag=0,shortcut=False)\n        self.conv1 = ConvBlock(k=3,s=2,p=1,dim=256,c=256)\n        self.conv2 = ConvBlock(k=3,s=2,p=1,dim=512,c=512)\n        \n    def forward(self, x_first, x_second, x_last):\n        \n        if DEBUG:\n            print(\"[Layer: SPPF 9]\")\n            print(f\"Input Tensor Shape:  {x_last.shape}\")\n        out_sppf = self.sppf(x_last)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {out_sppf.shape}\")\n\n            print(\"[Layer: Upsample 10]\")\n            print(f\"Input Tensor Shape:  {out_sppf.shape}\")\n        x = self.upsample1(out_sppf)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: Concat 11]\")\n            print(f\"Input Tensor Shape:  {x.shape}, {x_second.shape}\")\n        x = torch.cat((x,x_second), dim=1)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: C2f 12]\")\n            print(f\"Input Tensor Shape:  {x.shape}\")\n        conc1 = self.c2f_block1(x)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {conc1.shape}\")\n\n            print(\"[Layer: Upsample 13]\")\n            print(f\"Input Tensor Shape:  {conc1.shape}\")\n        x = self.upsample2(conc1)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: Concat 14]\")\n            print(f\"Input Tensor Shape:  {x.shape}, {x_first.shape}\")\n        x = torch.cat((x,x_first), dim=1)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: C2f 15]\")\n            print(f\"Input Tensor Shape:  {x.shape}\")\n        det1 = self.c2f_block2(x)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {det1.shape}\")\n\n            print(\"[Layer: Conv 16]\")\n            print(f\"Input Tensor Shape:  {det1.shape}\")\n        x = self.conv1(det1)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: Concat 17]\")\n            print(f\"Input Tensor Shape:  {x.shape}, {conc1.shape}\")\n        x = torch.cat((x,conc1), dim=1)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: C2f 18]\")\n            print(f\"Input Tensor Shape:  {x.shape}\")\n        det2 = self.c2f_block3(x)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {det2.shape}\")\n\n            print(\"[Layer: Conv 19]\")\n            print(f\"Input Tensor Shape:  {det2.shape}\")\n        x = self.conv2(det2)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: Concat 20]\")\n            print(f\"Input Tensor Shape:  {x.shape}, {out_sppf.shape}\")\n        x = torch.cat((x,out_sppf), dim=1)\n       \n        if DEBUG:\n            print(f\"Output Tensor Shape: {x.shape}\")\n\n            print(\"[Layer: C2f 21]\")\n            print(f\"Input Tensor Shape:  {x.shape}\")\n        det3 = self.c2f_block4(x)\n        if DEBUG:\n            print(f\"Output Tensor Shape: {det3.shape}\")\n        \n        return det1, det2, det3\n    \nclass Head(nn.Module):\n    def __init__(self):\n        super(Head, self).__init__()\n        \n        self.det1 = DetectBlock(c=256)\n        self.det2 = DetectBlock(c=512)\n        self.det3 = DetectBlock(c=512)\n        \n    def forward(self, x1, x2, x3):\n        return self.det1(x1), self.det2(x2), self.det3(x3)\n    \n    \nclass YOLO(nn.Module):\n    def __init__(self):\n        super(YOLO, self).__init__()\n        self.h1 = BackBone()\n        self.h2 = Neck()\n        self.h3 = Head()\n        \n    def forward(self, x): \n        \n        if DEBUG:\n            print(\"---------- Backbone ----------\")\n            print(\"[Backbone Input]\")\n            print(f\"Input Tensor Shape: {x.shape}\")\n        res1, res2, res3 = self.h1(x)\n        if DEBUG:\n            print(\"[Backbone Output]\")\n            print(f\"Output Tensor Shape: \\n\\t\\t     {res1.shape}, \\n\\t\\t     {res2.shape}, \\n\\t\\t     {res3.shape}\")\n            print(\"------------------------------\")\n\n        if DEBUG:\n            print(\"---------- Neck ----------\")\n            print(\"[Neck Input]\")\n            print(f\"Input Tensor Shape:  \\n\\t\\t     {res1.shape}, \\n\\t\\t     {res2.shape}, \\n\\t\\t     {res3.shape}\")\n        det1, det2, det3 = self.h2(res1, res2, res3)\n        if DEBUG:\n            print(\"[Neck Output]\")\n            print(f\"Output Tensor Shape: \\n\\t\\t     {det1.shape}, \\n\\t\\t     {det2.shape}, \\n\\t\\t     {det3.shape}\")\n            print(\"------------------------------\")\n\n        if DEBUG:\n            print(\"---------- Head ----------\")\n            print(\"[Head Input]\")\n            print(f\"Input Tensor Shape: \\n\\t\\t      {det1.shape}, \\n\\t\\t     {det2.shape}, \\n\\t\\t     {det3.shape}\")\n        det1, det2, det3 = self.h3(det1, det2, det3)\n        if DEBUG:\n            print(\"[Head Output]\")\n            print(f\"Output Tensor Bbox Loss: \\n\\t\\t     {det1[0].shape}, \\n\\t\\t     {det2[0].shape}, \\n\\t\\t     {det3[0].shape}\")\n            print(f\"Output Tensor Cls Loss: \\n\\t\\t     {det1[1].shape}, \\n\\t\\t     {det2[1].shape}, \\n\\t\\t     {det3[1].shape}\")\n            print(\"------------------------------\")\n\n        return det1, det2, det3\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:46:26.841165Z","iopub.execute_input":"2024-08-05T14:46:26.841879Z","iopub.status.idle":"2024-08-05T14:46:26.905448Z","shell.execute_reply.started":"2024-08-05T14:46:26.841848Z","shell.execute_reply":"2024-08-05T14:46:26.904713Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Initialize dataset and dataloader\n\nDEBUG = False\n\ncsv_file = '/kaggle/input/data/train_solution_bounding_boxes (1).csv'\nimg_dir = '/kaggle/input/data/training_images'\ntransform = transforms.Compose([\n    #data aug \n    transforms.Resize((380, 380)),\n    transforms.ToTensor(),\n])\n\nif DEBUG:\n    print(\"========================================\")\n    print(\"        YOLOv8 Model Debug Output       \")\n    print(\"========================================\")\nmodel = YOLO()\n\ndataset = YOLODataset(csv_file=csv_file, img_dir=img_dir, transform=transform)\ndataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n# Training loop\nnum_epochs = 50\nfor epoch in range(num_epochs):\n    print(f\"epoch = {epoch}\")\n    model.train()\n    running_loss = 0.0\n    for i, batch in enumerate(dataloader):\n        images = batch['image'].to(device)\n        targets = batch['label'].to(device)\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(images)\n        \n   \n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T14:46:26.907080Z","iopub.execute_input":"2024-08-05T14:46:26.907353Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"epoch = 0\nepoch = 1\n","output_type":"stream"}]}]}